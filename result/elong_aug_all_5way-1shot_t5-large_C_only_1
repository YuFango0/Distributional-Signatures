test_acc: 0.4524960211366415 
test_std: 0.09095341053558012 
val_acc: 0.49248002350330355 
val_std: 0.0855986594943598 
DA_path:  
DA_vocab: use_old 
aug_mode: None 
auxiliary: [] 
bert: False 
bert_cache_dir: None 
classifier: r2d2 
clip_grad: None 
cnn_filter_sizes: [3, 4, 5] 
cnn_num_filters: 50 
csv_path: elong_aug_all 
cuda: 1 
data_path: data/t5-large_huffpost_roberta-large-mnli_10N_top-k_40_C_only.json 
dataset: huffpost 
dropout: 0.1 
elongation: False 
embedding: meta 
finetune_ebd: False 
finetune_episodes: 10 
finetune_loss_type: softmax 
finetune_maxepochs: 5000 
finetune_split: 0.8 
induct_att_dim: 64 
induct_hidden_dim: 100 
induct_iter: 3 
induct_rnn_dim: 128 
lr: 0.001 
lrd2_num_iters: 5 
maml: False 
maml_batchsize: 10 
maml_firstorder: False 
maml_innersteps: 10 
maml_stepsize: 0.1 
meta_ebd: False 
meta_idf: False 
meta_iwf: True 
meta_target_entropy: False 
meta_w_target: True 
meta_w_target_lam: 1 
mlp_hidden: [300, 5] 
mode: train 
n_test_class: 16 
n_train_class: 20 
n_val_class: 5 
n_workers: 10 
nn_distance: l2 
notqdm: False 
patience: 20 
pos_ebd_dim: 5 
pos_max_len: 40 
pretrained_bert: None 
proto_hidden: [300, 300] 
query: 25 
result_path: result/elong_aug_all_5way-1shot_t5-large_C_only_1 
save: False 
seed: 42 
shot: 1 
snapshot:  
task_aug_exclude_test_query: False 
task_aug_exclude_val_query: False 
task_aug_target: train 
task_aug_test: False 
test_DA: False 
test_episodes: 1000 
test_new_only: False 
test_query_size: -1 
train_episodes: 100 
train_epochs: 1000 
use_query_DA: False 
use_support_DA: False 
val_episodes: 100 
way: 5 
word_vector: wiki.en.vec 
wv_path: ./ 
